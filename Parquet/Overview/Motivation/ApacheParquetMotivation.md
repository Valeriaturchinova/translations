## Мотивация

Apache Parquet был разработан, чтобы удовлетворить потребность разработчиков из экосистемы Hadoop в колоночном формате данных с возможностью их сжатия.

Parquet создан с учетом необходимости поддержки сложных структур данных. 
Он использует [алгоритм разбиения и восстановления данных](https://github.com/julienledem/redelm/wiki/The-striping-and-assembly-algorithms-from-the-Dremel-paper) из 
[статьи](https://research.google/pubs/pub36632/) про систему анализа данных Dremel. Ожидается, что этот алгоритм превосходит подход перевода вложенных структур данных к плоскому формату.

В Parquet обеспечена поддержка высокоэффективных алгоритмов 
сжатия и кодирования информации. Многочисленные проекты показывают прирост производительности
при использовании правильных схем сжатия и кодирования данных. 
Parquet позволяет указывать схемы сжатия на уровне каждого столбца, а также готов 
к добавлению новых схем кодирования по мере их изобретения и реализации.

Любой разработчик может использовать Parquet. 
В экосистеме Hadoop имеется большое количество фреймворков для обработки данных, 
и каждый их них важен по-своему. Эффективная колоночная структура хранения данных 
без сложных зависимостей может быть полезна для всех фреймворков. 